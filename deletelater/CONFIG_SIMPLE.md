# âœ… SIMPLE Configuration Architecture

## ğŸ¯ Keep It Simple!

For this simple Streamlit app, we use **direct environment variables** - no complex config classes needed!

---

## ğŸ“Š The Simple Flow

```
config.yaml (YOU EDIT)
    â†“
    â†“ [python generate_app_yaml.py dev]
    â†“
app/app.yaml (AUTO-GENERATED with env vars)
    â†“
    â†“ [Databricks Apps sets environment]
    â†“
os.getenv() in Python code (THAT'S IT!)
```

---

## ğŸ“ Files

### **You Edit**
- **`config.yaml`** - Source of truth for all configuration

### **Auto-Generated**
- **`app/app.yaml`** - Generated by `generate_app_yaml.py`
  - Contains all environment variables
  - DO NOT EDIT DIRECTLY

### **Helper Scripts**
- **`generate_app_yaml.py`** - Generates app.yaml from config.yaml
- **`deploy_with_config.sh`** - One-command deployment

---

## ğŸ’» Usage in Code

### **Main App (app_databricks.py)**
```python
import os

# Read environment variables (set by app.yaml)
CATALOG = os.getenv("CATALOG_NAME", "fraud_detection_dev")
SCHEMA = os.getenv("SCHEMA_NAME", "claims_analysis")
WAREHOUSE_ID = os.getenv("DATABRICKS_WAREHOUSE_ID", "148ccb90800933a1")
ENVIRONMENT = os.getenv("ENVIRONMENT", "dev")
LLM_ENDPOINT = os.getenv("LLM_ENDPOINT", "databricks-claude-sonnet-4-5")

# Use them
st.write(f"Catalog: {CATALOG}")
```

### **In Pages (pages/1_claim_analysis.py)**
```python
import os

# Read what you need
CATALOG = os.getenv("CATALOG_NAME", "fraud_detection_dev")
SCHEMA = os.getenv("SCHEMA_NAME", "claims_analysis")
WAREHOUSE_ID = os.getenv("DATABRICKS_WAREHOUSE_ID")

# Compute values if needed
CLAIMS_TABLE = f"{CATALOG}.{SCHEMA}.claims_data"

# Use them
df = execute_sql(f"SELECT * FROM {CLAIMS_TABLE}")
```

---

## ğŸš€ Workflow

### **Step 1: Edit Configuration**
```bash
vim config.yaml
```

Change any values:
```yaml
environments:
  dev:
    catalog: "fraud_detection_dev"
    warehouse_id: "148ccb90800933a1"
    llm_endpoint: "databricks-claude-sonnet-4-5"
```

### **Step 2: Generate app.yaml**
```bash
python generate_app_yaml.py dev
```

This creates `app/app.yaml` with environment variables:
```yaml
env:
  - name: 'CATALOG_NAME'
    value: 'fraud_detection_dev'
  - name: 'DATABRICKS_WAREHOUSE_ID'
    value: '148ccb90800933a1'
  # ... etc
```

### **Step 3: Deploy**
```bash
databricks bundle deploy --profile DEFAULT_azure
```

Or use the helper script:
```bash
./deploy_with_config.sh dev
```

### **Step 4: Use in Code**
```python
import os
catalog = os.getenv("CATALOG_NAME")  # Automatically set by Databricks Apps!
```

---

## ğŸ“‹ Available Environment Variables

After running `generate_app_yaml.py`, these variables are available via `os.getenv()`:

| Variable | Example Value | Purpose |
|----------|---------------|---------|
| `DATABRICKS_HOST` | `adb-984752964297111.11.azuredatabricks.net` | Workspace URL |
| `DATABRICKS_WAREHOUSE_ID` | `148ccb90800933a1` | SQL Warehouse ID |
| `CATALOG_NAME` | `fraud_detection_dev` | Unity Catalog name |
| `SCHEMA_NAME` | `claims_analysis` | Schema name |
| `VECTOR_ENDPOINT` | `one-env-shared-endpoint-2` | Vector Search endpoint |
| `LLM_ENDPOINT` | `databricks-claude-sonnet-4-5` | LLM model endpoint |
| `ENVIRONMENT` | `dev` | Environment name |
| `EMBEDDING_MODEL` | `databricks-gte-large-en` | Embedding model |

---

## ğŸ¯ Examples

### **Example 1: Read Config in Page**
```python
# app/pages/1_claim_analysis.py
import streamlit as st
import os

# Get config from environment
CATALOG = os.getenv("CATALOG_NAME", "fraud_detection_dev")
SCHEMA = os.getenv("SCHEMA_NAME", "claims_analysis")

# Compute table name
CLAIMS_TABLE = f"{CATALOG}.{SCHEMA}.claims_data"

# Use it
st.write(f"Analyzing claims from: {CLAIMS_TABLE}")
```

### **Example 2: Initialize Agent**
```python
# app/utils/fraud_agent.py
import os
from databricks_langchain import ChatDatabricks

class FraudAgent:
    def __init__(self):
        # Read from environment
        llm_endpoint = os.getenv("LLM_ENDPOINT", "databricks-claude-sonnet-4-5")
        catalog = os.getenv("CATALOG_NAME")
        schema = os.getenv("SCHEMA_NAME")
        
        # Initialize
        self.llm = ChatDatabricks(endpoint=llm_endpoint)
        self.config_table = f"{catalog}.{schema}.config_genie"
```

### **Example 3: Change Environment**
```bash
# Deploy to dev
python generate_app_yaml.py dev
databricks bundle deploy
# Uses: fraud_detection_dev

# Deploy to staging
python generate_app_yaml.py staging
databricks bundle deploy
# Uses: fraud_detection_staging
```

---

## ğŸ”§ Two Config Patterns in This Project

### **Pattern 1: Notebooks (Use shared/config.py)**
```python
# setup/01_create_catalog_schema.py
from shared.config import get_config

cfg = get_config()  # Reads config.yaml from filesystem
spark.sql(f"CREATE CATALOG {cfg.catalog}")
```

**Why**: Notebooks have filesystem access to read `config.yaml`

---

### **Pattern 2: Streamlit App (Use os.getenv())**
```python
# app/app_databricks.py
import os

CATALOG = os.getenv("CATALOG_NAME")  # Reads from environment
st.write(f"Catalog: {CATALOG}")
```

**Why**: Databricks Apps use environment variables (no filesystem access to config.yaml)

---

## ğŸ“Š Complete Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  config.yaml                           â”‚
â”‚  (Source of Truth - YOU EDIT)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                 â”‚            â”‚
           â–¼                 â–¼            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ generate_   â”‚   â”‚ shared/ â”‚  â”‚databricksâ”‚
    â”‚ app_yaml.py â”‚   â”‚config.pyâ”‚  â”‚   .yml   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚               â”‚            â”‚
           â–¼               â–¼            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
    â”‚ app/        â”‚  â”‚Notebooks â”‚     â”‚
    â”‚ app.yaml    â”‚  â”‚(Spark)   â”‚     â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
           â”‚                           â”‚
           â–¼                           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
    â”‚Environment  â”‚                   â”‚
    â”‚Variables    â”‚                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â”‚
           â”‚                           â”‚
           â–¼                           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  os.getenv() in Streamlit       â”‚
    â”‚  Simple and direct!             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Benefits of This Simple Approach

1. **Simple** - No complex config classes
2. **Pythonic** - Standard `os.getenv()` 
3. **Flexible** - Easy to add new variables
4. **Debuggable** - Print env vars anytime
5. **Portable** - Works anywhere env vars work

---

## ğŸš¨ Common Pattern (DRY)

If you want to avoid repeating env var reads, create a simple constants file:

```python
# app/constants.py (optional)
import os

# Read once
CATALOG = os.getenv("CATALOG_NAME", "fraud_detection_dev")
SCHEMA = os.getenv("SCHEMA_NAME", "claims_analysis")
WAREHOUSE_ID = os.getenv("DATABRICKS_WAREHOUSE_ID", "148ccb90800933a1")
LLM_ENDPOINT = os.getenv("LLM_ENDPOINT", "databricks-claude-sonnet-4-5")
VECTOR_ENDPOINT = os.getenv("VECTOR_ENDPOINT", "one-env-shared-endpoint-2")
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "databricks-gte-large-en")
ENVIRONMENT = os.getenv("ENVIRONMENT", "dev")

# Computed values (convenience)
CLAIMS_TABLE = f"{CATALOG}.{SCHEMA}.claims_data"
VECTOR_INDEX = f"{CATALOG}.{SCHEMA}.fraud_cases_index"
CONFIG_TABLE = f"{CATALOG}.{SCHEMA}.config_genie"
KNOWLEDGE_BASE_TABLE = f"{CATALOG}.{SCHEMA}.fraud_cases_kb"
```

Then import:
```python
from constants import CATALOG, SCHEMA, CLAIMS_TABLE
```

---

## ğŸ“ Quick Reference

```bash
# Generate app.yaml for environment
python generate_app_yaml.py [dev|staging|prod]

# Deploy with auto-generation
./deploy_with_config.sh [dev|staging|prod]

# Or manual steps
python generate_app_yaml.py dev
databricks bundle deploy --profile DEFAULT_azure
```

---

## ğŸ¯ Summary

**Simple Architecture**:
- âœ… `config.yaml` = source of truth
- âœ… `generate_app_yaml.py` = generates env vars
- âœ… `app.yaml` = contains env vars
- âœ… `os.getenv()` = read in Python
- âœ… No complex config classes!

**One file to edit, environment variables to read!**

---

**See CONFIG_FLOW_VISUAL.md for diagrams**

