{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ú®‚ú®‚ú® VERSION 2.4 - CREATED December 17, 2025 ‚ú®‚ú®‚ú®\n",
    "# LangGraph Agent Learning - Healthcare Fraud Detection\n",
    "\n",
    "**Purpose:** Learn LangGraph ReAct agents by wrapping existing UC Functions, Vector Search, and Genie API\n",
    "\n",
    "**Domain:** Healthcare insurance claims (Upcoding, Phantom Billing, Provider Networks)\n",
    "\n",
    "**Authentication:** Uses WorkspaceClient (same as dashboard) for realistic testing\n",
    "\n",
    "**Branch:** `main` (production-ready demo)\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ **NOTEBOOK VERSION INFO**\n",
    "\n",
    "**üìÖ Last Updated:** December 17, 2025\n",
    "**üîß Version:** 2.4 - WITH ARCHITECTURE DIAGRAMS\n",
    "**‚ú® New in 2.1:** Visual architecture diagrams throughout notebook\n",
    "**‚úÖ Status:** Production-ready educational demo\n",
    "\n",
    "**üö® VERIFICATION:** After running LLM init cell, you MUST see:\n",
    "```\n",
    "‚úÖ Tools bound to LLM (ensures proper JSON format)\n",
    "```\n",
    "\n",
    "**If you DON'T see this line ‚Üí Detach & Reattach notebook!**\n",
    "\n",
    "---\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "1. ‚úÖ Tests all 4 tools individually (UC Functions, Vector Search, Genie)\n",
    "2. ‚úÖ Wraps them as LangChain Tools\n",
    "3. ‚úÖ Creates LangGraph ReAct Agent\n",
    "4. ‚úÖ Tests agent with different claim complexities (simple ‚Üí suspicious ‚Üí complex)\n",
    "5. ‚úÖ Compares Sequential vs Agent approaches (cost optimization)\n",
    "\n",
    "**Goal:** Demonstrate how the fraud detection agent works under the hood\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Tutorial Architecture Overview\n",
    "\n",
    "![5-Layer Architecture](../docs/images/technical_architecture_5layers.png)\n",
    "\n",
    "*This tutorial teaches you to build the complete 5-layer architecture: from Databricks services (bottom) through LangChain tools, agents, ReAct pattern, up to LangGraph orchestration (top)*\n",
    "\n",
    "**Note:** If images don't display in your Databricks workspace, see the [Image Setup Guide](../docs/images/README.md) for workspace deployment instructions.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è The Four Tools You'll Build\n",
    "\n",
    "![Four Tool Architecture](../docs/images/4_tools_architecture.png)\n",
    "\n",
    "*Each tool wraps a Databricks service, giving the agent different capabilities: classification, extraction, search, and analytics*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup - Install Dependencies\n",
    "\n",
    "**Why these specific versions?**\n",
    "- `langgraph>=1.0.0` - Latest version (v1.0) removed `state_modifier` parameter\n",
    "- `langchain>=0.3.0` - Latest version with improved tool calling\n",
    "- Pinning versions ensures reproducibility across environments\n",
    "\n",
    "**Key packages:**\n",
    "- `langgraph` - State machine and agent orchestration\n",
    "- `langchain` - Agent framework and tool abstractions\n",
    "- `databricks-langchain` - Databricks-specific LangChain integrations\n",
    "- `unitycatalog-langchain` - Unity Catalog function integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langgraph>=1.0.0 langchain>=0.3.0 langchain-core>=0.3.0 langchain-community>=0.3.0 databricks-langchain unitycatalog-langchain[databricks] backoff databricks-sdk mlflow databricks-vectorsearch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Version Check - Run This First!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version check - Run this to verify you have the latest notebook\n",
    "import datetime\n",
    "print(\"=\" * 80)\n",
    "print(\"üîç NOTEBOOK VERSION CHECK\")\n",
    "print(\"=\" * 80)\n",
    "print(\"üìÖ Deployed Version: December 7, 2024 - 7:30 PM PST\")\n",
    "print(\"üîß Version: 2.1 - WITH ARCHITECTURE DIAGRAMS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚úÖ If you see this, the notebook file is the latest version!\")\n",
    "print(\"üé® NEW: Architecture diagrams embedded throughout notebook\")\n",
    "print(\"üö® After running LLM init, you MUST see: 'Tools bound to LLM'\")\n",
    "print(\"‚ùå If you don't see that line ‚Üí Detach & Reattach notebook\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Imports and Configuration\n",
    "\n",
    "**Import Strategy:**\n",
    "- `WorkspaceClient` - Databricks SDK for calling APIs (UC Functions, Genie, etc.)\n",
    "- `ChatDatabricks` - LangChain wrapper for Databricks Foundation Models\n",
    "- `VectorSearchClient` - For semantic search in fraud knowledge base\n",
    "- `SystemMessage` - LangChain message type for system prompts (v1.0+ pattern)\n",
    "- `create_react_agent` - Pre-built ReAct agent from LangGraph\n",
    "\n",
    "**Why these imports?**\n",
    "- All use WorkspaceClient pattern (same as dashboard) for portability\n",
    "- SystemMessage needed for manual prompt injection (v1.0+ requirement)\n",
    "- No custom state classes needed for this simple use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Databricks integrations\n",
    "from databricks.sdk import WorkspaceClient  # Unified API client\n",
    "from databricks_langchain import ChatDatabricks  # LLM wrapper\n",
    "from databricks.vector_search.client import VectorSearchClient  # Semantic search\n",
    "\n",
    "# LangChain/LangGraph components\n",
    "from langchain_core.tools import Tool  # Tool wrapper abstraction\n",
    "from langchain_core.messages import SystemMessage  # For system prompt injection\n",
    "from langgraph.prebuilt import create_react_agent  # Pre-built ReAct pattern\n",
    "\n",
    "# Additional imports for state management (if needed for advanced use)\n",
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import backoff  # For retry logic\n",
    "\n",
    "# Initialize WorkspaceClient (same pattern as dashboard)\n",
    "w = WorkspaceClient()\n",
    "\n",
    "print(\"‚úÖ WorkspaceClient initialized\")\n",
    "print(f\"üìç Workspace: {w.config.host}\")\n",
    "print(f\"üë§ Current user: {w.current_user.me().user_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration from config.yaml\n",
    "\n",
    "**Centralized Configuration Strategy:**\n",
    "- Uses `shared/config.py` module (same as dashboard and all setup notebooks)\n",
    "- Reads from `config.yaml` for single source of truth\n",
    "- Auto-detects environment (dev/staging/prod) from DAB widget or env variable\n",
    "- All settings (catalog, schema, warehouse, vector index, LLM) come from config\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ No hardcoded values - change `config.yaml` once, works everywhere\n",
    "- ‚úÖ Environment-specific settings (dev vs prod)\n",
    "- ‚úÖ Consistent with dashboard and setup notebooks\n",
    "- ‚úÖ Easy to maintain and update\n",
    "\n",
    "**LLM Endpoint:**\n",
    "- Production uses Claude Sonnet 4 for reliable function calling\n",
    "- Best JSON format compliance for tool calls\n",
    "- Configured per environment in `config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shared configuration module (same as dashboard and setup notebooks)\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from shared.config import get_config\n",
    "\n",
    "# Load configuration from config.yaml\n",
    "# Auto-detects environment from DAB widget, env variable, or uses default\n",
    "cfg = get_config()\n",
    "\n",
    "# Extract config values for notebook use\n",
    "CATALOG = cfg.catalog\n",
    "SCHEMA = cfg.schema\n",
    "WAREHOUSE_ID = cfg.warehouse_id\n",
    "INDEX_NAME = cfg.vector_index  # Already computed as {catalog}.{schema}.fraud_cases_index\n",
    "GENIE_SPACE_ID = cfg.genie_space_id\n",
    "LLM_ENDPOINT = cfg.llm_endpoint\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ CONFIGURATION LOADED FROM config.yaml\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"üåç Environment: {cfg.catalog.replace('fraud_detection_', '')}\")\n",
    "print(f\"üìö Catalog: {CATALOG}\")\n",
    "print(f\"üìä Schema: {SCHEMA}\")\n",
    "print(f\"üè¢ Warehouse ID: {WAREHOUSE_ID}\")\n",
    "print(f\"üîç Vector Index: {INDEX_NAME}\")\n",
    "print(f\"ü§ñ Genie Space: {GENIE_SPACE_ID}\")\n",
    "print(f\"üß† LLM Endpoint: {LLM_ENDPOINT}\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüí° TIP: Configuration is centralized in config.yaml\")\n",
    "print(\"   Change environment by passing to get_config('dev'/'prod')\")\n",
    "print(\"   Or set DAB widget 'environment' when deploying\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Test Individual Tools\n",
    "\n",
    "Before creating the agent, verify each tool works correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Tool 1: UC Function Wrapper (Classification & Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_uc_function(function_name: str, parameters: dict):\n",
    "    \"\"\"\n",
    "    Call a UC function using Statement Execution API (same as dashboard).\n",
    "    This is more reliable for Databricks Apps and notebooks.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from databricks.sdk.service.sql import StatementState\n",
    "        \n",
    "        print(f\"üîß Calling UC Function: {CATALOG}.{SCHEMA}.{function_name}\")\n",
    "        \n",
    "        # Build SQL query with parameters\n",
    "        param_values = []\n",
    "        for key, value in parameters.items():\n",
    "            if isinstance(value, str):\n",
    "                # Escape single quotes\n",
    "                escaped = value.replace(\"'\", \"''\")\n",
    "                param_values.append(f\"'{escaped}'\")\n",
    "            else:\n",
    "                param_values.append(str(value))\n",
    "        \n",
    "        args_str = ', '.join(param_values)\n",
    "        query = f\"SELECT {CATALOG}.{SCHEMA}.{function_name}({args_str}) as result\"\n",
    "        \n",
    "        print(f\"  üìù SQL: {query[:100]}...\")\n",
    "        \n",
    "        # Execute via Statement Execution API\n",
    "        response = w.statement_execution.execute_statement(\n",
    "            warehouse_id=WAREHOUSE_ID,\n",
    "            statement=query,\n",
    "            wait_timeout='30s'\n",
    "        )\n",
    "        \n",
    "        if response.status.state == StatementState.SUCCEEDED:\n",
    "            # Extract result from response\n",
    "            if response.result and response.result.data_array:\n",
    "                result_json = response.result.data_array[0][0]\n",
    "                result = json.loads(result_json) if isinstance(result_json, str) else result_json\n",
    "                print(f\"‚úÖ UC Function result received\")\n",
    "                return result\n",
    "            else:\n",
    "                print(f\"‚ùå No data in response\")\n",
    "                return {\"error\": \"No data returned\"}\n",
    "        else:\n",
    "            error_msg = response.status.error.message if response.status.error else \"Unknown error\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            return {\"error\": error_msg}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Exception calling UC function: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\"error\": error_msg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: fraud_classify\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 1: UC Function - fraud_classify\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_claim = \"Database connection timeout in production affecting all users\"\n",
    "classification_result = call_uc_function(\n",
    "    \"fraud_classify\",\n",
    "    {\"claim_text\": test_claim}\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Classification Result:\")\n",
    "print(json.dumps(classification_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: fraud_extract_indicators\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 2: UC Function - fraud_extract_indicators\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "metadata_result = call_uc_function(\n",
    "    \"fraud_extract_indicators\",\n",
    "    {\"claim_text\": test_claim}\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Metadata Extraction Result:\")\n",
    "print(json.dumps(metadata_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ Tool 3: UC Function - Fraud Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: fraud_generate_explanation\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 3: UC Function - fraud_generate_explanation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use results from previous tests\n",
    "is_fraudulent = False  # Routine office visit is legitimate\n",
    "fraud_type = \"None\"    # No fraud detected\n",
    "\n",
    "explanation_result = call_uc_function(\n",
    "    \"fraud_generate_explanation\",\n",
    "    {\n",
    "        \"claim_text\": test_claim,\n",
    "        \"is_fraudulent\": is_fraudulent,\n",
    "        \"fraud_type\": fraud_type\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\nüí¨ Fraud Explanation Result:\")\n",
    "print(json.dumps(explanation_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Tool 4: Vector Search Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_knowledge_base(query: str, num_results: int = 3):\n",
    "    \"\"\"\n",
    "    Search fraud knowledge base using Vector Search.\n",
    "    Same pattern as dashboard - directly portable!\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"üîç Searching fraud knowledge base: '{query[:50]}...'\")\n",
    "        \n",
    "        # Initialize VectorSearchClient (uses workspace client from environment)\n",
    "        vsc = VectorSearchClient()\n",
    "        \n",
    "        results = vsc.get_index(\n",
    "            index_name=INDEX_NAME\n",
    "        ).similarity_search(\n",
    "            query_text=query,\n",
    "            columns=[\"doc_id\", \"doc_type\", \"title\", \"content\"],\n",
    "            num_results=num_results\n",
    "        )\n",
    "        \n",
    "        docs = results.get('result', {}).get('data_array', [])\n",
    "        print(f\"‚úÖ Found {len(docs)} documents\")\n",
    "        \n",
    "        formatted_results = [\n",
    "            {\n",
    "                \"doc_id\": doc[0],\n",
    "                \"doc_type\": doc[1],\n",
    "                \"title\": doc[2],\n",
    "                \"content\": doc[3][:200] + \"...\" if len(doc[3]) > 200 else doc[3],\n",
    "                \"score\": doc[4] if len(doc) > 4 else None\n",
    "            }\n",
    "            for doc in docs\n",
    "        ]\n",
    "        \n",
    "        return formatted_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Vector Search Error: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Vector Search\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 3: Vector Search\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "search_query = \"billing fraud patterns and upcoding schemes\"\n",
    "search_results = search_knowledge_base(search_query)\n",
    "\n",
    "print(f\"\\nüìö Knowledge Base Results ({len(search_results)} documents):\")\n",
    "for i, doc in enumerate(search_results, 1):\n",
    "    print(f\"\\n{i}. üìÑ {doc['title']}\")\n",
    "    print(f\"   üìÇ Type: {doc['doc_type']}\")\n",
    "    print(f\"   üìù Content: {doc['content'][:150]}...\")\n",
    "    if doc.get('score'):\n",
    "        print(f\"   üéØ Score: {doc['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Tool 5: Genie Conversation API Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenieConversationTool:\n",
    "    \"\"\"\n",
    "    Genie Conversation API wrapper using WorkspaceClient.\n",
    "    Same class as dashboard - directly portable!\n",
    "    \"\"\"\n",
    "    def __init__(self, workspace_client: WorkspaceClient, space_id: str):\n",
    "        self.w = workspace_client\n",
    "        self.space_id = space_id\n",
    "        print(f\"[Genie] Initialized with space_id: {space_id}\")\n",
    "    \n",
    "    def start_conversation(self, question: str):\n",
    "        \"\"\"Start a new Genie conversation\"\"\"\n",
    "        try:\n",
    "            print(f\"[Genie] Starting conversation...\")\n",
    "            response = self.w.api_client.do(\n",
    "                'POST',\n",
    "                f'/api/2.0/genie/spaces/{self.space_id}/start-conversation',\n",
    "                body={'content': question}\n",
    "            )\n",
    "            \n",
    "            conversation_id = response.get('conversation_id')\n",
    "            message_id = response.get('message_id')\n",
    "            \n",
    "            print(f\"[Genie] ‚úÖ Started - conversation_id: {conversation_id}, message_id: {message_id}\")\n",
    "            \n",
    "            return {\n",
    "                'status': 'started',\n",
    "                'conversation_id': conversation_id,\n",
    "                'message_id': message_id\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"[Genie] ‚ùå Error starting conversation: {str(e)}\")\n",
    "            return {'status': 'error', 'error': str(e)}\n",
    "    \n",
    "    def poll_for_result(self, conversation_id: str, message_id: str, max_wait_seconds: int = 120):\n",
    "        \"\"\"Poll for query completion with exponential backoff\"\"\"\n",
    "        print(f\"[Genie] Polling for result (max {max_wait_seconds}s)...\")\n",
    "        start_time = time.time()\n",
    "        poll_interval = 2\n",
    "        poll_count = 0\n",
    "        \n",
    "        while time.time() - start_time < max_wait_seconds:\n",
    "            try:\n",
    "                poll_count += 1\n",
    "                response = self.w.api_client.do(\n",
    "                    'GET',\n",
    "                    f'/api/2.0/genie/spaces/{self.space_id}/conversations/{conversation_id}/messages/{message_id}'\n",
    "                )\n",
    "                \n",
    "                status = response.get('status')\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"[Genie] Poll #{poll_count} ({elapsed:.1f}s): Status = {status}\")\n",
    "                \n",
    "                if status == 'COMPLETED':\n",
    "                    print(f\"[Genie] ‚úÖ Query completed!\")\n",
    "                    return {'status': 'completed', 'response': response}\n",
    "                elif status == 'FAILED':\n",
    "                    error = response.get('error', {})\n",
    "                    print(f\"[Genie] ‚ùå Query failed: {error}\")\n",
    "                    return {'status': 'failed', 'response': response, 'error': error}\n",
    "                \n",
    "                time.sleep(poll_interval)\n",
    "                poll_interval = min(poll_interval * 1.2, 10)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"[Genie] ‚ö†Ô∏è Poll error: {str(e)}\")\n",
    "                time.sleep(poll_interval)\n",
    "        \n",
    "        print(f\"[Genie] ‚è±Ô∏è Timeout after {max_wait_seconds}s\")\n",
    "        return {'status': 'timeout', 'error': f'Query did not complete within {max_wait_seconds}s'}\n",
    "    \n",
    "    def query(self, question: str):\n",
    "        \"\"\"\n",
    "        Complete Genie query workflow: start ‚Üí poll ‚Üí extract results ‚Üí fetch data\n",
    "        Returns structured results with actual data rows or error message.\n",
    "        \"\"\"\n",
    "        print(f\"\\n[Genie] === Starting Genie Query ===\")\n",
    "        print(f\"[Genie] Question: {question[:100]}...\")\n",
    "        \n",
    "        # Step 1: Start conversation\n",
    "        start_result = self.start_conversation(question)\n",
    "        if start_result.get('status') != 'started':\n",
    "            error_msg = f\"Error starting conversation: {start_result.get('error')}\"\n",
    "            print(f\"[Genie] {error_msg}\")\n",
    "            return {\"error\": error_msg}\n",
    "        \n",
    "        conversation_id = start_result['conversation_id']\n",
    "        message_id = start_result['message_id']\n",
    "        \n",
    "        # Step 2: Poll for completion\n",
    "        poll_result = self.poll_for_result(conversation_id, message_id, max_wait_seconds=120)\n",
    "        \n",
    "        poll_status = poll_result.get('status')\n",
    "        \n",
    "        if poll_status == 'failed':\n",
    "            error_detail = poll_result.get('error', {}).get('message', 'Query execution failed')\n",
    "            error_msg = f\"Query failed: {error_detail}\"\n",
    "            print(f\"[Genie] {error_msg}\")\n",
    "            return {\"error\": error_msg}\n",
    "        \n",
    "        if poll_status != 'completed':\n",
    "            error_msg = f\"Query did not complete: {poll_result.get('error', poll_status)}\"\n",
    "            print(f\"[Genie] {error_msg}\")\n",
    "            return {\"error\": error_msg}\n",
    "        \n",
    "        # Step 3: Extract results from poll response\n",
    "        response = poll_result['response']\n",
    "        text_content = response.get('content', '')\n",
    "        attachments = response.get('attachments', [])\n",
    "        \n",
    "        print(f\"[Genie] Received response with {len(attachments)} attachments\")\n",
    "        \n",
    "        result = {\n",
    "            \"text\": text_content,\n",
    "            \"query\": None,\n",
    "            \"data\": None,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"message_id\": message_id\n",
    "        }\n",
    "        \n",
    "        # Step 4: Extract SQL query and attachment_id\n",
    "        if attachments:\n",
    "            attachment = attachments[0]\n",
    "            \n",
    "            # CRITICAL: Field is 'attachment_id', NOT 'id'!\n",
    "            attachment_id = attachment.get('attachment_id') or attachment.get('id')\n",
    "            print(f\"[Genie] Attachment ID: {attachment_id}\")\n",
    "            \n",
    "            # Extract SQL query\n",
    "            query_obj = attachment.get('query', {})\n",
    "            if isinstance(query_obj, dict):\n",
    "                result['query'] = query_obj.get('query') or query_obj.get('content')\n",
    "                if result['query']:\n",
    "                    print(f\"[Genie] Extracted SQL: {result['query'][:100]}...\")\n",
    "            \n",
    "            # Step 5: Fetch actual data using query-result endpoint\n",
    "            if attachment_id:\n",
    "                print(f\"[Genie] Calling query-result endpoint...\")\n",
    "                try:\n",
    "                    query_result_response = self.w.api_client.do(\n",
    "                        'GET',\n",
    "                        f'/api/2.0/genie/spaces/{self.space_id}/conversations/{conversation_id}/messages/{message_id}/query-result/{attachment_id}'\n",
    "                    )\n",
    "                    \n",
    "                    # Parse response - data is wrapped in 'statement_response'\n",
    "                    statement_response = query_result_response.get('statement_response', {})\n",
    "                    if statement_response:\n",
    "                        print(f\"[Genie] Found statement_response\")\n",
    "                        manifest = statement_response.get('manifest', {})\n",
    "                        if manifest:\n",
    "                            schema = manifest.get('schema', {})\n",
    "                            columns = schema.get('columns', [])\n",
    "                            column_names = [col.get('name') for col in columns]\n",
    "                            print(f\"[Genie] Found columns: {column_names}\")\n",
    "                            \n",
    "                            # Get data rows\n",
    "                            result_obj = statement_response.get('result', {})\n",
    "                            data_array = result_obj.get('data_array', [])\n",
    "                            print(f\"[Genie] Found {len(data_array)} data rows from Genie API\")\n",
    "                            \n",
    "                            if data_array:\n",
    "                                # Convert to list of dicts\n",
    "                                result['data'] = []\n",
    "                                for row in data_array:\n",
    "                                    row_dict = dict(zip(column_names, row))\n",
    "                                    result['data'].append(row_dict)\n",
    "                                print(f\"[Genie] ‚úÖ Successfully converted {len(result['data'])} rows\")\n",
    "                            else:\n",
    "                                print(f\"[Genie] No data_array in result\")\n",
    "                        else:\n",
    "                            print(f\"[Genie] No manifest in statement_response\")\n",
    "                    else:\n",
    "                        print(f\"[Genie] No statement_response in query result response\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"[Genie] Error calling query-result endpoint: {str(e)}\")\n",
    "        \n",
    "        # Step 6: FALLBACK - Execute SQL directly if we have query but no data\n",
    "        if result.get('query') and not result.get('data'):\n",
    "            print(f\"[Genie] FALLBACK: No data from Genie API, executing SQL directly...\")\n",
    "            result['used_fallback'] = True\n",
    "            try:\n",
    "                from databricks.sdk.service.sql import StatementState\n",
    "                \n",
    "                execute_response = self.w.statement_execution.execute_statement(\n",
    "                    warehouse_id=WAREHOUSE_ID,\n",
    "                    statement=result['query'],\n",
    "                    wait_timeout='30s'\n",
    "                )\n",
    "                \n",
    "                print(f\"[Genie] Fallback execution status: {execute_response.status.state}\")\n",
    "                \n",
    "                if execute_response.status.state == StatementState.SUCCEEDED:\n",
    "                    columns = execute_response.manifest.schema.columns if execute_response.manifest and execute_response.manifest.schema else []\n",
    "                    column_names = [col.name for col in columns]\n",
    "                    print(f\"[Genie] Fallback found columns: {column_names}\")\n",
    "                    \n",
    "                    if execute_response.result and execute_response.result.data_array:\n",
    "                        data_array = execute_response.result.data_array\n",
    "                        print(f\"[Genie] Fallback found {len(data_array)} data rows\")\n",
    "                        \n",
    "                        result['data'] = []\n",
    "                        for row in data_array:\n",
    "                            row_dict = dict(zip(column_names, row))\n",
    "                            result['data'].append(row_dict)\n",
    "                        print(f\"[Genie] ‚úÖ Fallback successfully converted {len(result['data'])} rows\")\n",
    "                else:\n",
    "                    error_msg = execute_response.status.error.message if execute_response.status.error else \"Unknown error\"\n",
    "                    print(f\"[Genie] Fallback execution failed: {error_msg}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[Genie] Fallback execution error: {str(e)}\")\n",
    "        \n",
    "        print(f\"[Genie] Final data rows extracted: {len(result.get('data') or [])}\")\n",
    "        \n",
    "        # Determine which method was used\n",
    "        if result.get('data'):\n",
    "            if result.get('used_fallback'):\n",
    "                result['method'] = 'Direct SQL Execution (Fallback)'\n",
    "            else:\n",
    "                result['method'] = 'Genie query-result API'\n",
    "            print(f\"[Genie] Method: {result['method']}\")\n",
    "        \n",
    "        print(f\"[Genie] === Genie Query Complete ===\\n\")\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Genie API\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 5: Genie API\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "genie = GenieConversationTool(w, GENIE_SPACE_ID)\n",
    "genie_question = \"Show me the top 5 claims with the highest amounts\"\n",
    "genie_result = genie.query(genie_question)\n",
    "\n",
    "print(f\"\\nü§ñ Genie Result:\")\n",
    "print(f\"  üìù Text Response: {genie_result.get('text', '')[:300]}...\")\n",
    "if genie_result.get('query'):\n",
    "    print(f\"  üîç Generated SQL: {genie_result['query'][:200]}...\")\n",
    "if genie_result.get('data'):\n",
    "    print(f\"  üìä Data Rows: {len(genie_result['data'])}\")\n",
    "    print(f\"  üîß Method: {genie_result.get('method', 'Unknown')}\")\n",
    "    print(f\"\\n  Sample rows:\")\n",
    "    for i, row in enumerate(genie_result['data'][:3], 1):\n",
    "        print(f\"    {i}. {row}\")\n",
    "elif genie_result.get('error'):\n",
    "    print(f\"  ‚ùå Error: {genie_result['error']}\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è No data returned (query generated but data not fetched)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Create LangChain Tools\n",
    "\n",
    "Wrap the working functions as LangChain Tools for the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß∞ Wrap Functions as LangChain Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CREATING LANGCHAIN TOOLS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define Pydantic schemas for tool inputs (fixes LLM parameter naming issues)\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "class ClassifyClaimInput(BaseModel):\n",
    "    claim_text: str = Field(description=\"The insurance claim text to classify for fraud\")\n",
    "\n",
    "class ExtractMetadataInput(BaseModel):\n",
    "    claim_text: str = Field(description=\"The insurance claim text to extract fraud indicators from\")\n",
    "\n",
    "class SearchKnowledgeInput(BaseModel):\n",
    "    query: str = Field(description=\"The search query to find relevant fraud patterns and documentation\")\n",
    "\n",
    "class ExplainFraudInput(BaseModel):\n",
    "    claim_text: str = Field(description=\"The insurance claim text\")\n",
    "    is_fraudulent: str = Field(description=\"'true' if fraudulent, 'false' if legitimate\")\n",
    "    fraud_type: str = Field(description=\"Type of fraud detected (e.g., 'Upcoding', 'Phantom Billing')\")\n",
    "\n",
    "class QueryHistoricalInput(BaseModel):\n",
    "    question: str = Field(description=\"Natural language question about historical fraud claims\")\n",
    "\n",
    "# Tool 1: Classification\n",
    "def classify_claim_wrapper(claim_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Wrapper for fraud_classify UC Function.\n",
    "    \n",
    "    IMPORTANT: This function MUST be pure (no side effects)!\n",
    "    - ‚ùå NO Streamlit calls (st.info, st.error, etc.) - causes NoSessionContext error\n",
    "    - ‚úÖ Return JSON string only\n",
    "    - ‚úÖ Include error handling in return value\n",
    "    \n",
    "    WHY: LangGraph runs tools in background threads without Streamlit session context\n",
    "    \"\"\"\n",
    "    result = call_uc_function(\"fraud_classify\", {\"claim_text\": claim_text})\n",
    "    return json.dumps(result, indent=2) if result else json.dumps({\"error\": \"Classification failed\"})\n",
    "\n",
    "classify_tool = Tool(\n",
    "    name=\"classify_claim\",\n",
    "    description=\"Classifies an insurance claim as fraudulent or legitimate with fraud probability, type, and confidence score. Use this FIRST to assess fraud risk. Returns JSON with is_fraud, fraud_probability, fraud_type, confidence, key_indicators.\",\n",
    "    func=classify_claim_wrapper,\n",
    "    args_schema=ClassifyClaimInput\n",
    ")\n",
    "print(\"‚úÖ Tool 1: classify_claim\")\n",
    "\n",
    "# Tool 2: Metadata Extraction\n",
    "def extract_metadata_wrapper(claim_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Wrapper for fraud_extract_indicators UC Function.\n",
    "    IMPORTANT: Pure function - no Streamlit calls! (See classify_claim_wrapper for details)\n",
    "    \"\"\"\n",
    "    result = call_uc_function(\"fraud_extract_indicators\", {\"claim_text\": claim_text})\n",
    "    return json.dumps(result, indent=2) if result else json.dumps({\"error\": \"Extraction failed\"})\n",
    "\n",
    "extract_tool = Tool(\n",
    "    name=\"extract_metadata\",\n",
    "    description=\"Extracts detailed fraud indicators from claims including red flags, suspicious patterns, affected entities, and risk scores. Use for suspicious or high-value claims to identify specific fraud signals. Returns JSON with red_flags, suspicious_patterns, affected_entities, risk_score.\",\n",
    "    func=extract_metadata_wrapper,\n",
    "    args_schema=ExtractMetadataInput\n",
    ")\n",
    "print(\"‚úÖ Tool 2: extract_metadata\")\n",
    "\n",
    "# Tool 3: Knowledge Base Search\n",
    "def search_knowledge_wrapper(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Wrapper for Vector Search.\n",
    "    IMPORTANT: Pure function - no Streamlit calls! (See classify_claim_wrapper for details)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = search_knowledge_base(query, num_results=3)\n",
    "        return json.dumps(results, indent=2) if results else json.dumps([])\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Search failed: {str(e)}\"})\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"search_knowledge\",\n",
    "    description=\"Searches the fraud knowledge base for similar fraud cases, patterns, and schemes using semantic search. Use to find historical fraud cases with similar indicators or patterns. Returns JSON array with doc_id, title, content, doc_type for top matches.\",\n",
    "    func=search_knowledge_wrapper,\n",
    "    args_schema=SearchKnowledgeInput\n",
    ")\n",
    "print(\"‚úÖ Tool 3: search_knowledge\")\n",
    "\n",
    "# Tool 4: Fraud Explanation\n",
    "def explain_fraud_wrapper(claim_text: str, is_fraudulent: str, fraud_type: str) -> str:\n",
    "    \"\"\"\n",
    "    Wrapper for fraud_generate_explanation UC Function.\n",
    "    IMPORTANT: Pure function - no Streamlit calls! (See classify_claim_wrapper for details)\n",
    "    \"\"\"\n",
    "    # Convert string boolean to actual boolean for UC function\n",
    "    is_fraud_bool = is_fraudulent.lower() == 'true'\n",
    "    result = call_uc_function(\"fraud_generate_explanation\", {\n",
    "        \"claim_text\": claim_text,\n",
    "        \"is_fraudulent\": is_fraud_bool,\n",
    "        \"fraud_type\": fraud_type\n",
    "    })\n",
    "    return json.dumps(result, indent=2) if result else json.dumps({\"error\": \"Explanation failed\"})\n",
    "\n",
    "explain_tool = StructuredTool(\n",
    "    name=\"explain_fraud\",\n",
    "    description=\"Generates human-readable explanation for fraud decisions. Use AFTER classify and extract to explain WHY a claim is fraudulent or legitimate. Requires claim_text, is_fraudulent (true/false), and fraud_type. Returns JSON with explanation, evidence, and recommendations.\",\n",
    "    func=explain_fraud_wrapper,\n",
    "    args_schema=ExplainFraudInput\n",
    ")\n",
    "print(\"‚úÖ Tool 4: explain_fraud\")\n",
    "\n",
    "\n",
    "\n",
    "# Tool 5: Historical Trends (Genie API - Educational)\n",
    "def query_historical_wrapper(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Wrapper for Genie Conversation API.\n",
    "    NOTE: This is for educational purposes - shows how to integrate Genie as a tool.\n",
    "    IMPORTANT: Pure function - no Streamlit calls! (See classify_claim_wrapper for details)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        genie = GenieConversationTool(w, GENIE_SPACE_ID)\n",
    "        result = genie.query(question)\n",
    "        return json.dumps(result, indent=2, default=str)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Historical query failed: {str(e)}\"})\n",
    "\n",
    "genie_tool = Tool(\n",
    "    name=\"query_historical\",\n",
    "    description=\"Queries historical fraud claims database using natural language to find patterns, statistics, and trends. Use for educational demonstration of Genie API integration. Returns JSON with text summary and optionally SQL query used.\",\n",
    "    func=query_historical_wrapper,\n",
    "    args_schema=QueryHistoricalInput\n",
    ")\n",
    "print(\"‚úÖ Tool 5: query_historical (Genie - Educational)\")\n",
    "\n",
    "print(f\"\\nüéâ All 5 LangChain Tools created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Create LangGraph ReAct Agent\n",
    "\n",
    "Build the agent that will intelligently decide which tools to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Initialize LLM and Create Agent\n",
    "\n",
    "**Critical LangGraph v1.0+ Pattern:**\n",
    "This is the **main fix** that made the agent work!\n",
    "\n",
    "**What Changed in LangGraph v1.0:**\n",
    "- ‚ùå Old: `state_modifier` parameter (removed in v1.0)\n",
    "- ‚úÖ New: Pass SystemMessage in messages array at invocation time\n",
    "\n",
    "**Why This Approach:**\n",
    "1. **Compatible** - Works with LangGraph v1.0+\n",
    "2. **Explicit** - Clear what messages are sent to LLM\n",
    "3. **Flexible** - Can change system prompt per invocation if needed\n",
    "4. **Simple** - No complex state management required\n",
    "\n",
    "**Alternative Approaches (for reference):**\n",
    "- LangGraph v0.2: Used `state_modifier` parameter\n",
    "- LangGraph v1.0 advanced: Use custom `StateGraph` with preprocessor\n",
    "- LangChain v1.0: Use `langchain.claims_analysis.create_agent()` with state_schema\n",
    "\n",
    "We chose the simplest approach that works across versions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CREATING LANGGRAPH REACT AGENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# System prompt for the agent\n",
    "# This guides the agent's decision-making process\n",
    "# Key insight: Agent should be EFFICIENT, not exhaustive\n",
    "system_prompt = \"\"\"You are an expert healthcare fraud detection analyst.\n",
    "\n",
    "Your goal is to efficiently analyze insurance claims for fraud - using only the tools \n",
    "that provide valuable fraud assessment information for each specific claim.\n",
    "\n",
    "GUIDELINES:\n",
    "1. ALWAYS classify the claim first to assess fraud risk and probability\n",
    "2. For simple, low-value claims with low fraud probability, classification alone is often sufficient\n",
    "3. For suspicious or high-value claims (>$10K), extract detailed fraud indicators\n",
    "4. For claims with multiple red flags, search the fraud knowledge base for similar fraud patterns\n",
    "5. For complex fraud schemes or provider pattern analysis, query historical fraud data\n",
    "6. Be efficient but thorough - only use tools that add value to the fraud assessment\n",
    "\n",
    "Think step-by-step, explain your reasoning, and make smart decisions about which tools to use.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize LLM\n",
    "# ChatDatabricks is a LangChain wrapper for Databricks Foundation Models\n",
    "# It handles authentication via WorkspaceClient automatically\n",
    "llm = ChatDatabricks(\n",
    "    endpoint=LLM_ENDPOINT,  # Foundation model serving endpoint\n",
    "    temperature=0.1,  # VERY LOW temp for reliable tool calling (was 0.3, reduced to 0.1)\n",
    "    max_tokens=4096  # Sufficient for reasoning + tool calls\n",
    ")\n",
    "print(f\"‚úÖ LLM initialized: {LLM_ENDPOINT}\")\n",
    "\n",
    "# Create ReAct agent with all 4 tools\n",
    "# ReAct = Reasoning + Acting (agent thinks before acting)\n",
    "# Pattern: Thought ‚Üí Action (tool call) ‚Üí Observation (tool result) ‚Üí repeat\n",
    "tools_list = [classify_tool, extract_tool, search_tool, explain_tool, genie_tool]\n",
    "\n",
    "# üö® CRITICAL FIX: Use bind_tools for reliable function calling\n",
    "# This ensures the LLM uses proper JSON format (not XML) for ALL tool calls\n",
    "# Without this, Claude might hallucinate XML format mid-conversation\n",
    "llm_with_tools = llm.bind_tools(tools_list)\n",
    "print(f\"‚úÖ Tools bound to LLM (ensures proper JSON format)\")\n",
    "\n",
    "# Create the agent using the standard create_react_agent\n",
    "# IMPORTANT: Pass the bound LLM (llm_with_tools) not the raw LLM\n",
    "# This ensures consistent tool calling format throughout the conversation\n",
    "agent = create_react_agent(\n",
    "    model=llm_with_tools,  # The LLM with tools bound (CRITICAL!)\n",
    "    tools=tools_list  # Available tools the agent can call\n",
    "    # NOTE: We do NOT pass state_modifier here (deprecated in v1.0)\n",
    "    # Instead, we'll inject SystemMessage when we invoke the agent\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ LangGraph ReAct Agent created!\")\n",
    "print(f\"üß∞ Agent has 5 tools available:\")\n",
    "print(f\"   1. classify_claim\")\n",
    "print(f\"   2. extract_metadata\")\n",
    "print(f\"   3. search_knowledge\")\n",
    "print(f\"   4. explain_fraud\")\n",
    "print(f\"   5. query_historical (Genie - Educational)\")\n",
    "print(f\"\\nüéØ Agent will decide which tools to use based on the claim!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Test Agent with Different Claims\n",
    "\n",
    "See how the agent adapts to different claim complexities\n",
    "\n",
    "## üîÑ How the ReAct Pattern Works\n",
    "\n",
    "![ReAct Pattern Execution](../docs/images/flowchart_showing_react_claim.png)\n",
    "\n",
    "*The agent loops through Reason ‚Üí Act ‚Üí Observe ‚Üí Decide until it has enough information to provide a complete answer*\n",
    "\n",
    "**Key Points:**\n",
    "- Simple claims use 2-3 tools (fast, cheap)\n",
    "- Complex claims use all 4 tools (thorough, accurate)\n",
    "- Agent decides adaptively based on claim content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test Runner Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_test(claim_text: str, show_reasoning: bool = True):\n",
    "    \"\"\"\n",
    "    Test agent with a claim and display results\n",
    "    \n",
    "    This function demonstrates the LangGraph v1.0+ invocation pattern\n",
    "    \n",
    "    **Key Pattern: Manual SystemMessage Injection**\n",
    "    We pass the system prompt as the FIRST message when invoking the agent.\n",
    "    This is the v1.0+ replacement for the deprecated state_modifier parameter.\n",
    "    \n",
    "    Args:\n",
    "        claim_text: The support claim to analyze\n",
    "        show_reasoning: Whether to display the agent's thought process\n",
    "        \n",
    "    Returns:\n",
    "        Agent result containing messages and tool calls\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"üìã CLAIM: {claim_text}\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # CRITICAL PATTERN: Manual SystemMessage Injection (v1.0+)\n",
    "    # We explicitly pass SystemMessage as first message\n",
    "    # This replaces the old state_modifier approach from v0.2\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [\n",
    "            # System message goes FIRST - sets agent behavior/personality\n",
    "            SystemMessage(content=system_prompt),\n",
    "            # Then user message with the actual task\n",
    "            (\"user\", f\"Analyze this insurance claim for potential fraud: {claim_text}\")\n",
    "        ]\n",
    "    })\n",
    "    # The agent will:\n",
    "    # 1. Read system prompt (guidance)\n",
    "    # 2. Read user message (task)\n",
    "    # 3. Reason about what tools to call\n",
    "    # 4. Call tools as needed\n",
    "    # 5. Synthesize final answer\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    if show_reasoning:\n",
    "        print(\"üß† AGENT REASONING TRAIL:\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for i, message in enumerate(result['messages']):\n",
    "            msg_type = getattr(message, 'type', None)\n",
    "            \n",
    "            if msg_type == \"human\":\n",
    "                print(f\"\\nüë§ USER:\")\n",
    "                content = getattr(message, 'content', '')\n",
    "                print(f\"   {str(content)[:200]}...\")\n",
    "            elif msg_type == \"ai\":\n",
    "                content = getattr(message, 'content', '') or \"\"\n",
    "                # Check if this is a tool call or final answer\n",
    "                tool_calls = getattr(message, 'tool_calls', None)\n",
    "                if tool_calls:\n",
    "                    print(f\"\\nü§ñ AGENT THOUGHT & ACTION:\")\n",
    "                    if content:\n",
    "                        print(f\"   {str(content)[:300]}...\")\n",
    "                    for tool_call in tool_calls:\n",
    "                        tool_name = tool_call.get('name') if isinstance(tool_call, dict) else getattr(tool_call, 'name', 'unknown')\n",
    "                        tool_args = tool_call.get('args') if isinstance(tool_call, dict) else getattr(tool_call, 'args', {})\n",
    "                        print(f\"   üîß Calling tool: {tool_name}\")\n",
    "                        print(f\"   üì• Input: {str(tool_args)[:150]}...\")\n",
    "                else:\n",
    "                    print(f\"\\nü§ñ AGENT FINAL ANSWER:\")\n",
    "                    if content:\n",
    "                        print(f\"   {str(content)[:500]}...\")\n",
    "                    else:\n",
    "                        print(f\"   (No answer generated)\")\n",
    "            elif msg_type == \"tool\":  # Tool message\n",
    "                tool_name = getattr(message, 'name', 'unknown')\n",
    "                print(f\"\\nüì§ TOOL RESULT ({tool_name}):\")\n",
    "                content = getattr(message, 'content', None)\n",
    "                if content:\n",
    "                    result_preview = str(content)[:200] if len(str(content)) > 200 else str(content)\n",
    "                    print(f\"   {result_preview}...\")\n",
    "                else:\n",
    "                    print(f\"   (No content)\")\n",
    "    \n",
    "    # Count tools used\n",
    "    tool_messages = [m for m in result['messages'] if getattr(m, 'type', None) == 'tool']\n",
    "    tools_used = list(set([getattr(m, 'name', None) for m in tool_messages if getattr(m, 'name', None)]))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"üìä SUMMARY:\")\n",
    "    print(f\"   ‚è±Ô∏è  Time: {elapsed_time:.2f}s\")\n",
    "    if tools_used:\n",
    "        print(f\"   üß∞ Tools used: {len(tools_used)}/4 - {', '.join(tools_used)}\")\n",
    "    else:\n",
    "        print(f\"   üß∞ Tools used: 0/4\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test 1: Simple Legitimate Claim (Expected: 2 tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ TEST 1: SIMPLE LEGITIMATE CLAIM\")\n",
    "print(\"Expected behavior: Should use classify + search, skip extract and genie\\n\")\n",
    "\n",
    "result_1 = run_agent_test(\"Routine office visit for annual checkup. Patient: Mary Johnson. Amount: $150. Provider: Community Health Clinic. Date: 3/20/2024.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test 2: High-Risk Fraud Claim (Expected: 4 tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ TEST 2: HIGH-RISK FRAUD CLAIM\")\n",
    "print(\"Expected behavior: Should use classify + extract + search + genie (all 4 tools)\\n\")\n",
    "\n",
    "result_2 = run_agent_test(\"Emergency room visit for chest pain. Patient: Robert Wilson. Amount: $125,000. Provider: St. Mary's Hospital. Services include: cardiac catheterization, angioplasty, stent placement, ICU stay (5 days), multiple consultations. Billed to Medicare. Date: 3/10/2024.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test 3: Suspicious Fraud Pattern (Expected: 3 tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ TEST 3: SUSPICIOUS FRAUD PATTERN\")\n",
    "print(\"Expected behavior: Should use classify + extract + search (3 tools)\\n\")\n",
    "\n",
    "result_3 = run_agent_test(\"Physical therapy sessions for back pain. Patient: Susan Martinez. Provider: Wellness PT Center. Frequency: 3x per week for 8 weeks (24 sessions total). Amount: $18,000. Same diagnosis code repeated across all sessions. Dates: 2/1/2024 - 3/31/2024.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Sequential vs Agent Comparison\n",
    "\n",
    "Compare the agent approach with the current sequential pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Sequential Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_pipeline(claim_text: str):\n",
    "    \"\"\"\n",
    "    Run all 4 tools sequentially (current dashboard approach).\n",
    "    Always executes all tools regardless of claim complexity.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üîÑ SEQUENTIAL PIPELINE - Running ALL tools\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = {}\n",
    "    \n",
    "    # Step 1: Classify\n",
    "    print(\"1Ô∏è‚É£ Step 1: Classifying claim...\")\n",
    "    results['classification'] = call_uc_function(\"fraud_classify\", {\"claim_text\": claim_text})\n",
    "    print(f\"   ‚úÖ Done\\n\")\n",
    "    \n",
    "    # Step 2: Extract\n",
    "    print(\"2Ô∏è‚É£ Step 2: Extracting metadata...\")\n",
    "    results['metadata'] = call_uc_function(\"fraud_extract_indicators\", {\"claim_text\": claim_text})\n",
    "    print(f\"   ‚úÖ Done\\n\")\n",
    "    \n",
    "    # Step 3: Search\n",
    "    print(\"3Ô∏è‚É£ Step 3: Searching fraud knowledge base...\")\n",
    "    results['knowledge'] = search_knowledge_base(claim_text)\n",
    "    print(f\"   ‚úÖ Done\\n\")\n",
    "    \n",
    "    # Step 4: Genie\n",
    "    print(\"4Ô∏è‚É£ Step 4: Querying historical claims via Genie...\")\n",
    "    genie = GenieConversationTool(w, GENIE_SPACE_ID)\n",
    "    results['historical'] = genie.query(f\"Find similar resolved claims about: {claim_text}\")\n",
    "    print(f\"   ‚úÖ Done\\n\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üìä SEQUENTIAL SUMMARY:\")\n",
    "    print(f\"   ‚è±Ô∏è  Time: {elapsed_time:.2f}s\")\n",
    "    print(f\"   üß∞ Tools used: 4/4 (always all tools)\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    return results, elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üÜö Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"üÜö\" * 40)\n",
    "print(\"COMPARISON TEST: Sequential vs Agent\")\n",
    "print(\"üÜö\" * 40 + \"\\n\")\n",
    "\n",
    "comparison_claim = \"Prescription claim for diabetes medication. Patient: James Lee. Medication: Insulin glargine. Quantity: 90-day supply. Amount: $2,500. Pharmacy: QuickRx Pharmacy. Refilled 5 times in 3 months. Date: 3/25/2024.\"\n",
    "\n",
    "print(\"üìã Testing with claim:\")\n",
    "print(f\"   '{comparison_claim}'\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Run Sequential\n",
    "print(\"\\nüÖ∞Ô∏è APPROACH A: SEQUENTIAL PIPELINE (Current Dashboard)\")\n",
    "sequential_result, seq_time = sequential_pipeline(comparison_claim)\n",
    "\n",
    "# Run Agent\n",
    "print(\"\\nüÖ±Ô∏è APPROACH B: LANGGRAPH AGENT (New Adaptive)\")\n",
    "agent_result = run_agent_test(comparison_claim, show_reasoning=True)\n",
    "\n",
    "# Extract agent time and tools\n",
    "agent_tools = [getattr(m, 'name', None) for m in agent_result['messages'] if getattr(m, 'type', None) == 'tool']\n",
    "agent_tools_unique = list(set([t for t in agent_tools if t]))\n",
    "\n",
    "print(\"\\n\" + \"üÜö\" * 40)\n",
    "print(\"COMPARISON RESULTS\")\n",
    "print(\"üÜö\" * 40 + \"\\n\")\n",
    "\n",
    "print(\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(\"‚îÇ Metric                  ‚îÇ Sequential       ‚îÇ Agent            ‚îÇ\")\n",
    "print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "print(f\"‚îÇ Tools Used              ‚îÇ 4/4 (100%)       ‚îÇ {len(agent_tools_unique)}/4 ({len(agent_tools_unique)*25}%)        ‚îÇ\")\n",
    "print(f\"‚îÇ Efficiency              ‚îÇ Fixed pipeline   ‚îÇ Adaptive         ‚îÇ\")\n",
    "print(f\"‚îÇ Predictability          ‚îÇ High             ‚îÇ Medium           ‚îÇ\")\n",
    "print(f\"‚îÇ Flexibility             ‚îÇ None             ‚îÇ High             ‚îÇ\")\n",
    "print(\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "\n",
    "print(\"\\nüí° INSIGHTS:\")\n",
    "if len(agent_tools_unique) < 5:\n",
    "    print(f\"   ‚úÖ Agent was more efficient: used {len(agent_tools_unique)}/5 tools vs 5/5\")\n",
    "    print(f\"   ‚úÖ Agent skipped: {set(['classify_claim', 'extract_metadata', 'search_knowledge', 'explain_fraud', 'query_historical']) - set(agent_tools_unique)}\")\n",
    "    print(f\"   üí∞ Potential cost savings: ~{(5-len(agent_tools_unique))*20}%\")\n",
    "else:\n",
    "    print(f\"   ‚ÑπÔ∏è  Agent used all tools for this complex claim\")\n",
    "    print(f\"   ‚ÑπÔ∏è  For simple claims, agent would be more efficient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚úÖ Summary & Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Success Criteria Checklist\n",
    "\n",
    "If you've successfully run all cells above, you have:\n",
    "\n",
    "- ‚úÖ **Tool 1 Working:** UC Function (fraud_classify) with WorkspaceClient\n",
    "- ‚úÖ **Tool 2 Working:** UC Function (fraud_extract_indicators) with WorkspaceClient\n",
    "- ‚úÖ **Tool 3 Working:** Vector Search with WorkspaceClient\n",
    "- ‚úÖ **Tool 4 Working:** Genie Conversation API with WorkspaceClient\n",
    "- ‚úÖ **All 4 LangChain Tools Created:** Successfully wrapped APIs\n",
    "- ‚úÖ **LangGraph ReAct Agent Created:** Agent with 4 tools and system prompt\n",
    "- ‚úÖ **Agent Makes Decisions:** Tested with different claim complexities\n",
    "- ‚úÖ **Comparison Complete:** Sequential vs Agent side-by-side\n",
    "- ‚úÖ **Code is Portable:** Everything uses WorkspaceClient (same as dashboard)\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Key Learnings\n",
    "\n",
    "**What We Learned:**\n",
    "1. **Agent adapts to claim complexity** - uses fewer tools for simple questions\n",
    "2. **Tool descriptions matter** - they guide the agent's decision-making\n",
    "3. **System prompt is critical** - sets the agent's behavior and efficiency\n",
    "4. **ReAct pattern works** - Thought ‚Üí Action ‚Üí Observation loop is visible\n",
    "5. **Trade-offs are real** - flexibility vs predictability\n",
    "\n",
    "**When to Use Each Approach:**\n",
    "- **Sequential:** Predictable, uniform claims; need consistency\n",
    "- **Agent:** Varied complexity claims; want cost optimization\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "**Phase 2: Dashboard Integration**\n",
    "\n",
    "Now that the agent works in the notebook, we can:\n",
    "\n",
    "1. ‚úÖ Extract working code to `dashboard/langraph_agent.py` module\n",
    "2. ‚úÖ Add 5th tab to dashboard: \"üß™ LangGraph Agent (Experimental)\"\n",
    "3. ‚úÖ Display agent reasoning trail in Streamlit UI\n",
    "4. ‚úÖ Add comparison mode in dashboard\n",
    "5. ‚úÖ Deploy and test in production\n",
    "\n",
    "**Ready to move to dashboard integration!** üéØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                                                                ‚ïë\n",
    "‚ïë  üéâ LANGGRAPH AGENT NOTEBOOK COMPLETE! üéâ                     ‚ïë\n",
    "‚ïë                                                                ‚ïë\n",
    "‚ïë  ‚úÖ All 4 tools tested and working                            ‚ïë\n",
    "‚ïë  ‚úÖ LangGraph ReAct Agent created                             ‚ïë\n",
    "‚ïë  ‚úÖ Agent makes intelligent decisions                         ‚ïë\n",
    "‚ïë  ‚úÖ Sequential vs Agent comparison done                       ‚ïë\n",
    "‚ïë  ‚úÖ Code is ready for dashboard integration                   ‚ïë\n",
    "‚ïë                                                                ‚ïë\n",
    "‚ïë  üìç Branch: agent_langraph_trying                             ‚ïë\n",
    "‚ïë  üìÅ Notebook: notebooks/23_langraph_agent_learning.py         ‚ïë\n",
    "‚ïë                                                                ‚ïë\n",
    "‚ïë  üöÄ Ready for Phase 2: Dashboard Integration!                 ‚ïë\n",
    "‚ïë                                                                ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "02_fraud_agent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
